{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Onnx vs PyTorch example\n",
    "\n",
    "This example loads an event inspired by ProtoDUNE-SP simulated data and puts it\n",
    "through the `DUNEdn` denoising pipeline.\n",
    "\n",
    "The models implemented in PyTorch are exported to Onnx format and both are used\n",
    "to make inference separately.\n",
    "\n",
    "The outputs are then exploited to make accuracy and performance comparisons.\n",
    "\n",
    "- **Accuracy**  \n",
    "  Denoised events are analysed against ground truth labels from Monte\n",
    "  Carlo simulation.  \n",
    "  Four different metrics (namely `mse`, `psnr`, `ssim` and `iMAE`) are evaluated\n",
    "  as in the [paper](https://doi.org/10.1007/s41781-021-00077-9).\n",
    "- **Performance**  \n",
    "  The elapsed time for PyTorch and Onnx models batch prediction is measured for\n",
    "  different batch sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from plot_event_example import plot_example\n",
    "from assets.functions import (\n",
    "    check_in_output_folder,\n",
    "    inference,\n",
    "    compare_performance_onnx,\n",
    "    plot_comparison_catplot,\n",
    ")\n",
    "from dunedn.inference.hitreco import DnModel\n",
    "from dunedn.inference.analysis import analysis_main\n",
    "from dunedn.utils.utils import load_runcard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define user inputs.\n",
    "\n",
    "The user might want to tweak the following variables to experiment with the `DUNEdn` package.\n",
    "\n",
    "- **modeltype** -> available options: `cnn`, `gcnn`, `uscg`.\n",
    "- **version**  -> available options: `v08`, `v09`  \n",
    "  The dataset version where the model was trained on.  \n",
    "  For `cnn` and `gcnn` networks, only version `v08` is available.\n",
    "- **pytorch_dev** -> available options: `cpu`, `cuda:0` or `cuda:id`.  \n",
    "  The device hosting the PyTorch computation.  \n",
    "  It is recommended to run PyTorch on a GPU.  \n",
    "  Default ``batch_size`` settings ensure that the computation fits a 16 GB gpu.  \n",
    "- **base_folder** -> the output folder.  \n",
    "  Ensure to have permissions to write on the device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user inputs\n",
    "modeltype = \"cnn\"\n",
    "version = \"v08\"\n",
    "pytorch_dev = \"cuda:0\"  # device hosting PyTorch computation\n",
    "base_folder = Path(\"../../output/tmp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base folders\n",
    "ckpt_folder = Path(f\"../saved_models/{modeltype}_{version}\")\n",
    "\n",
    "# relative folders\n",
    "folders = {\n",
    "    \"base\": base_folder,\n",
    "    \"out\": base_folder / \"models/onnx\",\n",
    "    \"ckpt\": ckpt_folder,\n",
    "    \"cards\": base_folder / f\"cards\",\n",
    "    \"onnx_save\": base_folder / f\"models/onnx/saved_models/{modeltype}_{version}\",\n",
    "    \"plot\": base_folder / \"models/onnx/plots\",\n",
    "    \"id_plot\": base_folder / \"models/onnx/plots/identity\",\n",
    "    \"pytorch_plot\": base_folder / \"models/onnx/plots/torch\",\n",
    "    \"onnx_plot\": base_folder / \"models/onnx/plots/onnx\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to files\n",
    "paths = {\n",
    "    \"input\": folders[\"out\"] / \"p2GeV_cosmics_inspired_rawdigit_evt8.npy\",\n",
    "    \"target\": folders[\"out\"] / \"p2GeV_cosmics_inspired_rawdigit_noiseoff_evt8.npy\",\n",
    "    \"pytorch\": folders[\"out\"]\n",
    "    / f\"p2GeV_cosmics_inspired_rawdigit_torch_{modeltype}_evt8.npy\",\n",
    "    \"onnx\": folders[\"out\"]\n",
    "    / f\"p2GeV_cosmics_inspired_rawdigit_onnx_{modeltype}_evt8.npy\",\n",
    "    \"performance_csv\": folders[\"out\"] / f\"{modeltype}_performance_comparison.csv\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_in_output_folder(folders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_example(\n",
    "    paths[\"input\"], paths[\"target\"], outdir=folders[\"id_plot\"], with_graphics=True\n",
    ")\n",
    "\n",
    "evt = np.load(paths[\"input\"])[:, 2:]\n",
    "print(f\"Loaded event at {paths['input']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch inference\n",
    "\n",
    "### Model loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup = load_runcard(base_folder / \"cards/runcard.yaml\")  # settings\n",
    "model = DnModel(setup, modeltype, ckpt_folder)\n",
    "print(f\"Loaded model from {ckpt_folder} folder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_time = inference(model, evt, paths[\"pytorch\"], pytorch_dev)\n",
    "print(f\"PyTorch inference done in {pytorch_time}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis: accuracy assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute metrics\n",
    "analysis_main(paths[\"pytorch\"], paths[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make plot\n",
    "plot_example(\n",
    "    paths[\"pytorch\"],\n",
    "    paths[\"target\"],\n",
    "    outdir=folders[\"pytorch_plot\"],\n",
    "    with_graphics=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Onnx inference\n",
    "\n",
    "### Export to and load model from Onnx format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "model.onnx_export(folders[\"onnx_save\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model_onnx = DnModel(setup, modeltype, folders[\"onnx_save\"], should_use_onnx=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Onnx inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONNX inference\n",
    "onnx_time = inference(model_onnx, evt, paths[\"onnx\"])\n",
    "print(f\"ONNX inference done in {onnx_time}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis: accuracy assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute metrics\n",
    "analysis_main(paths[\"onnx\"], paths[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make plot\n",
    "plot_example(\n",
    "    paths[\"onnx\"], paths[\"target\"], outdir=folders[\"onnx_plot\"], with_graphics=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch vs Onnx Performance\n",
    "\n",
    "The goal is to compare the performance of the models for different input batch sizes.\n",
    "\n",
    "The collected inference timings are loaded into a `Pandas.Dataframe` for easier manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_list = [32, 64, 128, 256, 512]\n",
    "nb_batches = 5\n",
    "performance_df = compare_performance_onnx(\n",
    "    model, model_onnx, pytorch_dev, batch_size_list, nb_batches\n",
    ")\n",
    "performance_df.to_csv(paths[\"performance_csv\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_df = pd.read_csv(paths[\"performance_csv\"]).set_index([\"batch\", \"value\"])\n",
    "plot_comparison_catplot(performance_df, folders[\"plot\"], with_graphics=True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e80351b5c4fff56b32463330d4c3134db2ccc1cad158f50be317425bad0b8b08"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('dn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
