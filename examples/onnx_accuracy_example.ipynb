{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Onnx vs PyTorch example\n",
    "\n",
    "This example loads an event inspired by ProtoDUNE-SP simulated data and puts it\n",
    "through the `DUNEdn` denoising pipeline.\n",
    "\n",
    "The models implemented in PyTorch are exported to Onnx format and both are used\n",
    "to make inference separately.\n",
    "\n",
    "Denoised events are analysed against ground truth labels from Monte Carlo\n",
    "simulation.  \n",
    "Four different metrics (namely `mse`, `psnr`, `ssim` and `iMAE`) are evaluated\n",
    "as in the [paper](https://doi.org/10.1007/s41781-021-00077-9).\n",
    "\n",
    "The image below shows the pipeline adopted for the current example. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\">\n",
    "<img src=\"assets/accuracy.png\" alt=\"Onnx accuracy example\" width=60%/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from plot_event_example import plot_example\n",
    "from assets.functions import (\n",
    "    prepare_folders_and_paths,\n",
    "    check_in_output_folder,\n",
    "    inference,\n",
    ")\n",
    "from dunedn.inference.hitreco import DnModel\n",
    "from dunedn.inference.analysis import analysis_main\n",
    "from dunedn.utils.utils import load_runcard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define user inputs.\n",
    "\n",
    "The user might want to tweak the following variables to experiment with the `DUNEdn` package.\n",
    "\n",
    "- **modeltype** -> available options: `cnn`, `gcnn`, `uscg`.\n",
    "- **version**  -> available options: `v08`, `v09`  \n",
    "  The dataset version where the model was trained on.  \n",
    "  For `cnn` and `gcnn` networks, only version `v08` is available.\n",
    "- **pytorch_dev** -> available options: `cpu`, `cuda:0` or `cuda:id`.  \n",
    "  The device hosting the PyTorch computation.  \n",
    "  It is recommended to run PyTorch on a GPU.  \n",
    "  Default ``batch_size`` settings ensure that the computation fits a 16 GB gpu.  \n",
    "- **base_folder** -> the output folder.  \n",
    "  Ensure to have permissions to write on the device.\n",
    "- **ckpt_folder** -> the checkpoint folder.  \n",
    "  Ensure the folder has the structure explained in the package documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user inputs\n",
    "modeltype = \"cnn\"\n",
    "version = \"v08\"\n",
    "pytorch_dev = \"cpu\"  # device hosting PyTorch computation\n",
    "base_folder = Path(\"../../output/tmp\")\n",
    "ckpt_folder = Path(f\"../saved_models/{modeltype}_{version}\")\n",
    "\n",
    "# set up the environment\n",
    "folders, paths = prepare_folders_and_paths(modeltype, version, base_folder, ckpt_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create output directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_in_output_folder(folders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_example(\n",
    "    paths[\"input\"], paths[\"target\"], outdir=folders[\"id_plot\"], with_graphics=True\n",
    ")\n",
    "\n",
    "evt = np.load(paths[\"input\"])[:, 2:]\n",
    "print(f\"Loaded event at {paths['input']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model loading: PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup = load_runcard(base_folder / \"cards/runcard.yaml\")  # settings\n",
    "model = DnModel(setup, modeltype, ckpt_folder)\n",
    "print(f\"Loaded model from {ckpt_folder} folder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model loading: Onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "model.onnx_export(folders[\"onnx_save\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model_onnx = DnModel(setup, modeltype, folders[\"onnx_save\"], should_use_onnx=True)\n",
    "print(f\"Loaded model from {folders['onnx_save']} folder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_time = inference(model, evt, paths[\"pytorch\"], pytorch_dev)\n",
    "print(f\"PyTorch inference done in {pytorch_time}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis: accuracy assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute metrics\n",
    "analysis_main(paths[\"pytorch\"], paths[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make plot\n",
    "plot_example(\n",
    "    paths[\"pytorch\"],\n",
    "    paths[\"target\"],\n",
    "    outdir=folders[\"pytorch_plot\"],\n",
    "    with_graphics=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Onnx inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_time = inference(model_onnx, evt, paths[\"onnx\"])\n",
    "print(f\"ONNX inference done in {onnx_time}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis: accuracy assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute metrics\n",
    "analysis_main(paths[\"onnx\"], paths[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make plot\n",
    "plot_example(\n",
    "    paths[\"onnx\"], paths[\"target\"], outdir=folders[\"onnx_plot\"], with_graphics=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e80351b5c4fff56b32463330d4c3134db2ccc1cad158f50be317425bad0b8b08"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('dn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
